{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Divergences of Semi-Synthetic datasets in OpenML \n",
    "### Example: https://www.openml.org/d/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from util import *\n",
    "sns.set()\n",
    "sns.set_style('white')\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = '../Shannon/datasets_parsed.pickle'\n",
    "with open(pickle_file, \"rb\") as input_file:\n",
    "    datasets = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "X0, X1 = datasets[idx][\"X0\"], datasets[idx][\"X1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 5)\n",
      "(432, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X0.shape)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating the Total Variation/ Chi-Squared Divergence From Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neuron = 30\n",
    "dx = X0.shape[1]\n",
    "lr = 1e-2\n",
    "epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_W1 = tf.Variable(xavier_init([dx, num_neuron]), name='G_W1')\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[num_neuron]), name='G_b1')\n",
    "G_W2 = tf.Variable(xavier_init([num_neuron, num_neuron]), name='G_W2')\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[num_neuron]), name='G_b2')\n",
    "G_W3 = tf.Variable(xavier_init([num_neuron, num_neuron]), name='G_W3')\n",
    "G_b3 = tf.Variable(tf.zeros(shape=[num_neuron]), name='G_b3')\n",
    "G_W4 = tf.Variable(xavier_init([num_neuron, 1]), name='G_W4')\n",
    "G_b4 = tf.Variable(tf.zeros(shape=[1]), name='G_b4')\n",
    "theta_G = [G_W1, G_b1, G_W2, G_b2, G_W3, G_b3, G_W4, G_b4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_approx(data):\n",
    "    fc1 = tf.nn.relu(tf.matmul(data, G_W1) + G_b1)\n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, G_W2) + G_b2)\n",
    "    fc3 = tf.nn.relu(tf.matmul(fc2, G_W3) + G_b3)\n",
    "    # fc4 = tf.nn.relu(tf.matmul(fc3, G_W4) + G_b4)\n",
    "    # g = tf.matmul(fc4, G_W5) + G_b5\n",
    "    g = tf.matmul(fc3, G_W4) + G_b4\n",
    "\n",
    "    clip_min = np.float32(-.5)\n",
    "    clip_max = np.float32(.5)\n",
    "    g_clip = tf.clip_by_value(g, clip_min, clip_max)\n",
    "    return g_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_divergence(data1, data2):\n",
    "    M1 = g_approx(data1)\n",
    "    M2 = g_approx(data2)\n",
    "    sup_loss = tf.reduce_mean(M1) - tf.reduce_mean(M2)\n",
    "    return sup_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\t loss\n",
      "0\t 0.00000000\n",
      "100\t 0.00000000\n",
      "200\t 0.00000000\n",
      "300\t 0.00000000\n",
      "400\t 0.00000000\n",
      "500\t 0.00000000\n",
      "600\t 0.00000000\n",
      "700\t 0.00000000\n",
      "800\t 0.00000000\n",
      "900\t 0.00000000\n"
     ]
    }
   ],
   "source": [
    "# Initiate the session for training\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Placeholders for data from two populations\n",
    "data1 = tf.placeholder(tf.float32, [None, dx])\n",
    "data2 = tf.placeholder(tf.float32, [None, dx])\n",
    "\n",
    "# Compute mutual information\n",
    "TV = tv_divergence(data1, data2)\n",
    "TV_loss = -1*TV\n",
    "solver_TV = tf.train.AdagradOptimizer(lr).minimize(TV_loss, var_list = theta_G)\n",
    "\n",
    "# Initialization\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Training \n",
    "print('epoch\\t loss')\n",
    "for i in range(epoch):\n",
    "    _, current_loss = sess.run([solver_TV, TV_loss], feed_dict={data1: X1, data2: X0})\n",
    "    if i % 100 == 0:\n",
    "        print('{}\\t {:.8f}'.format(i, -current_loss))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
